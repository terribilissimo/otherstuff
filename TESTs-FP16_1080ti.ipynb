{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# GTX1080ti: test FP32 vs. FP16\n",
    "\n",
    "#### Pay attention: Same data for FP32 and FP16, but the batch size is doubled in the latter case.\n",
    "\n",
    "TL;DR version:\n",
    "\n",
    "FP32: bs=105, vram occupation peaks at `10074` Mb, wall time: 1:45\n",
    "\n",
    "FP16: bs=210, vram occupation peaks at `10162` Mb, wall time: 1:37\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX 1080 Ti (11176 RAM)\n",
      "\n",
      "\n",
      "*** Current state:\n",
      "RAM:    Used    Free   Total       Util\n",
      "CPU:   1,870  92,729  96,560 MB   1.94% \n",
      "GPU:     560  10,615  11,176 MB   5.02% \n",
      "\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.000\n",
      "･ CPU:          0          0      1,871 MB |\n",
      "･ GPU:          0          0        560 MB |\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import re\n",
    "import scipy.ndimage\n",
    "from ipyexperiments import *\n",
    "import fastai\n",
    "fastai.__version__\n",
    "\n",
    "path    = Path('/home/DATA/data/')\n",
    "fp32exp = IPyExperimentsPytorch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.808\n",
      "･ CPU:          2          2      1,981 MB |\n",
      "･ GPU:          0          0        560 MB |\n"
     ]
    }
   ],
   "source": [
    "path = Path('/home/DATA/data/')\n",
    "bs=105\n",
    "data = ImageDataBunch.from_folder(path,\n",
    "                                  train='backup224',\n",
    "                                  valid='backup224valid',\n",
    "                                  size=224, bs=bs,\n",
    "                                  ).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:01.791\n",
      "･ CPU:          0          0      2,093 MB |\n",
      "･ GPU:        106          0        666 MB |\n"
     ]
    }
   ],
   "source": [
    "learn = create_cnn(data, models.resnet50, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:45 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.064476</th>\n",
       "    <th>0.440659</th>\n",
       "    <th>0.867703</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.636661</th>\n",
       "    <th>0.116766</th>\n",
       "    <th>0.968158</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.386443</th>\n",
       "    <th>0.045268</th>\n",
       "    <th>0.989007</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.244284</th>\n",
       "    <th>0.023008</th>\n",
       "    <th>0.999242</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.161967</th>\n",
       "    <th>0.020775</th>\n",
       "    <th>0.999242</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.6 s, sys: 54.4 s, total: 1min 37s\n",
      "Wall time: 1min 45s\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:01:45.978\n",
      "･ CPU:          0          0      2,136 MB |\n",
      "･ GPU:        282     10,074        948 MB |\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Kernel is now restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX 1080 Ti (11176 RAM)\n",
      "\n",
      "\n",
      "*** Current state:\n",
      "RAM:    Used    Free   Total       Util\n",
      "CPU:   1,868  92,730  96,560 MB   1.94% \n",
      "GPU:     560  10,615  11,176 MB   5.02% \n",
      "\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.000\n",
      "･ CPU:          0          0      1,869 MB |\n",
      "･ GPU:          0          0        560 MB |\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import re\n",
    "import scipy.ndimage\n",
    "from ipyexperiments import *\n",
    "import fastai\n",
    "fastai.__version__\n",
    "\n",
    "path    = Path('/home/DATA/data/')\n",
    "fp16exp = IPyExperimentsPytorch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:01.371\n",
      "･ CPU:          3          2      2,049 MB |\n",
      "･ GPU:          0          0        560 MB |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = Path('/home/DATA/data/')\n",
    "bs=210\n",
    "data = ImageDataBunch.from_folder(path,\n",
    "                                  train='backup224',\n",
    "                                  valid='backup224valid',\n",
    "                                  size=224, bs=bs,\n",
    "                                  ).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:01.804\n",
      "･ CPU:          0          0      2,094 MB |\n",
      "･ GPU:         82         32        642 MB |\n"
     ]
    }
   ],
   "source": [
    "learn = create_cnn(data, models.resnet50, metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:37 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.203099</th>\n",
       "    <th>0.464430</th>\n",
       "    <th>0.860500</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.855579</th>\n",
       "    <th>0.214616</th>\n",
       "    <th>0.948825</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.598909</th>\n",
       "    <th>0.096289</th>\n",
       "    <th>0.982183</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.433335</th>\n",
       "    <th>0.060937</th>\n",
       "    <th>0.987491</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.331232</th>\n",
       "    <th>0.056734</th>\n",
       "    <th>0.990144</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.4 s, sys: 42.6 s, total: 1min 18s\n",
      "Wall time: 1min 37s\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:01:37.449\n",
      "･ CPU:          0          0      2,137 MB |\n",
      "･ GPU:        160     10,162        802 MB |\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
